{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSXtPck7qONj",
    "outputId": "eb341c4a-344c-4ff6-ab93-b82b7b55f43d"
   },
   "source": [
    "# Before You Start\n",
    "\n",
    "1. You will need Credentials to Silverpond's PyPi server. Contact your Customer Success team member if you don't have one.\n",
    "2. Highlighter API Token. If you don't already have one you can do the following:\n",
    "  - Login to Highlighter\n",
    "  - Click on the User Icon üë§ and click their name in the dropdown menu\n",
    "  - Click Request Access Token (At the bottom). This token will be valid until it is deleted\n",
    "  - Save the token somewhere safe\n",
    "3. You'll need a GPU to do training If in Google Colab be sure select a GPU runtime\n",
    "4. If in Google Colab be sure when the Install Packaged cell completes it may ask you to restart the runtime. Click the button and **do not** re-run the cell again.\n",
    "5. The Install Packages cell will take ~5-10min to run.\n",
    "\n",
    "# This notebook\n",
    "\n",
    "- Installs packages\n",
    "- Exports data from Highlighter\n",
    "- Inspects exported data\n",
    "- Samples data into train and test splits\n",
    "- Saves data to Coco format\n",
    "- Configures mmdetection Faster-RCNN model for training\n",
    "- Trains model\n",
    "- Exports model to Open Neural Network Exchange (ONNX)\n",
    "- Use the exported ONNX model to preform inference on an image from your test set\n",
    "\n",
    "# Helpful Links\n",
    "\n",
    "- [mmdetection github](https://github.com/open-mmlab/mmdetection)\n",
    "- [read the docs](https://mmdetection.readthedocs.io/en/v2.18.0/)\n",
    "- [mmcv github](https://github.com/open-mmlab/mmcv)\n",
    "\n",
    "\n",
    "# Install Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWkYiA4ydTJl",
    "outputId": "3ed561c7-fbda-489e-b5f1-e2e03d39c4a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def i_am_running_in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "if i_am_running_in_colab():\n",
    "    %env PYPI_USERNAME=rick_sanchez\n",
    "    %env PYPI_PASSWORD=WubbaLubbaDubDub\n",
    "    !git clone https://github.com/silverpond/highlighter-client-v2-notebooks.git\n",
    "    !bash highlighter-client-v2-notebooks/colab-scripts/setup-train-mmdet.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a9jw3uSeP3H"
   },
   "source": [
    "# House Keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvgAZ5k6W7S6",
    "outputId": "387f0ccd-9a41-4225-bc0c-54a96a5aa49c"
   },
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# # Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_jUmZFgYUD3"
   },
   "outputs": [],
   "source": [
    "HL_WEB_GRAPHQL_API_TOKEN=\"<HIGHLIGHTER_API_TOKEN>\"\n",
    "HL_WEB_GRAPHQL_ENDPOINT=\"https://<ACCOUNT_NAME>.highlighter.ai/graphql\"\n",
    "\n",
    "dataset_id = 191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0UUUeuy_mMb"
   },
   "outputs": [],
   "source": [
    "from highlighter_client.gql_client import HLClient\n",
    "\n",
    "# Small helper function for displaying the DataFrames in the highlighter clinet\n",
    "# dataset object\n",
    "def display_ds(ds, count=10):\n",
    "    display(ds.annotations_df.head(count))\n",
    "    display(ds.images_df.head(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5xgoT06YVuG"
   },
   "source": [
    "# Download data using Highlighter Client.\n",
    "\n",
    "For a more detailed run through of how to use HighlighterClient see the [export-submissions](https://github.com/tall-josh/highlighter-client-v2-notebooks/blob/main/export-submissions.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqchyF93W7S-",
    "outputId": "c4439c97-f301-4d3e-ba3a-8b4e6415db38"
   },
   "outputs": [],
   "source": [
    "from highlighter_client.datasets import get_reader, get_writer\n",
    "from highlighter_client.datasets.dataset import Dataset\n",
    "from highlighter_client.base_models import DatasetSubmissionTypeConnection\n",
    "from highlighter_client.paginate import paginate\n",
    "\n",
    "ds = Dataset(\n",
    "    reader=get_reader(\"highlighter_submissions\")(),\n",
    "    writer=get_writer(\"coco\")(),\n",
    ")\n",
    "\n",
    "client = HLClient.from_credential(api_token=HL_WEB_GRAPHQL_API_TOKEN, endpoint_url=HL_WEB_GRAPHQL_ENDPOINT)\n",
    "\n",
    "submissions_gen = paginate(\n",
    "client.datasetSubmissionConnection,\n",
    "DatasetSubmissionTypeConnection,\n",
    "datasetId=dataset_id,\n",
    ")\n",
    "\n",
    "print(\"This could take a minute\")\n",
    "ds.read(submissions_gen=submissions_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "id": "1Q1bTTxbzDQL",
    "outputId": "cf9f28a5-d2cb-4056-847d-887c858a338a"
   },
   "outputs": [],
   "source": [
    "display_ds(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7w2osZBLW7TA"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "At this point you may wish to do some pre-processing eg:\n",
    "\n",
    "  - **remove unwanted classes**: You may wish to filter some annotations from your dataset\n",
    "  - **split the data**: notice the `split` column is only a single value *data*. We can apply a random split before saving to `coco` format.\n",
    "\n",
    "To keep things general we will simply split the data into **train** and **test** in this notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b7LP_4S3W7TA",
    "outputId": "4b348610-f9db-4221-a305-33fe9229799b"
   },
   "outputs": [],
   "source": [
    "train_frac = 0.8\n",
    "ds.images_df[\"split\"] = \"train\"\n",
    "\n",
    "test_ids = ds.images_df.sample(frac=1-train_frac, random_state=42).image_id\n",
    "ds.images_df.loc[ds.images_df.image_id.isin(test_ids), \"split\"] = \"test\"\n",
    "ds.images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFJhpReJW7TB"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "image_dir = Path(\"data/images\")\n",
    "annotations_dir = Path(\"data/annotatoins\")\n",
    "\n",
    "image_dir.mkdir(parents=True, exist_ok=True)\n",
    "annotations_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ds.write(annotations_dir=annotations_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O98pgx9FW7TC",
    "outputId": "1aaa740f-1515-48a7-ced4-b38e9e6926a0"
   },
   "outputs": [],
   "source": [
    "from highlighter_client.io import multithread_graphql_image_download\n",
    "\n",
    "result = multithread_graphql_image_download(\n",
    "    client,\n",
    "    list(ds.images_df.image_id.values),\n",
    "    image_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qyzAchwW7TC"
   },
   "source": [
    "# Check the json files exported correctly\n",
    "\n",
    "We'll also get the number of categories in the training data. We will need it\n",
    "when we configure the mmdet model for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D88wpmwLW7TD",
    "outputId": "7dbd1942-c074-4898-a6e2-707bd99e2723"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with (annotations_dir/\"train.json\").open('r') as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "# We'll use this later when configuring the mmdet frcnn model\n",
    "categories = train_data[\"categories\"]\n",
    "sorted(categories, key = lambda i: i[\"id\"])\n",
    "\n",
    "num_classes = len(categories)\n",
    "\n",
    "for c in categories:\n",
    "    print(c)\n",
    "    \n",
    "CLASSES = [i[\"name\"] for i in categories]\n",
    "\n",
    "print(f\"num_images: {len(train_data['images'])}\")\n",
    "print(f\"num_annos: {len(train_data['annotations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFQvdnVftSWT"
   },
   "source": [
    "# Confirgure MMDetection Model for training\n",
    "\n",
    "For more info on how to configure mmdet models see their docs. This is a good place to start https://mmdetection.readthedocs.io/en/latest/tutorials/config.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ad95HUzIW7TE",
    "outputId": "092e20fe-d2a0-4669-efd8-24f40ace3c94"
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "import mmcv\n",
    "\n",
    "# Your checkpoints and configuration will be saved in this directory\n",
    "work_dir = \"work_dir\"\n",
    "\n",
    "# Keep it small for demo purposes. You're welcome to bump this up\n",
    "# if you're down to party\n",
    "num_epochs = 2\n",
    "\n",
    "mmdet_config = dict(\n",
    "    work_dir = work_dir,\n",
    "    gpu_ids = [0],\n",
    "    seed = 42,\n",
    "    runner = dict(max_epochs=num_epochs),\n",
    "    data = dict(\n",
    "        train = dict(\n",
    "            ann_file=str(annotations_dir / \"train.json\"),\n",
    "            img_prefix=str(image_dir),\n",
    "            classes=CLASSES,\n",
    "        ),\n",
    "        val = dict(\n",
    "            ann_file=str(annotations_dir / \"test.json\"),\n",
    "            img_prefix=str(image_dir),\n",
    "            classes=CLASSES,\n",
    "        ),\n",
    "        test = dict(\n",
    "            ann_file=str(annotations_dir / \"test.json\"),\n",
    "            img_prefix=str(image_dir),\n",
    "            classes=CLASSES,\n",
    "        ),\n",
    "    ),\n",
    "    model = dict(\n",
    "        roi_head = dict(\n",
    "            bbox_head = dict(\n",
    "                num_classes = num_classes,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "cfg = Config.fromfile(\"mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py\")\n",
    "cfg.merge_from_dict(mmdet_config)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# Save config\n",
    "cfg.dump(f\"{work_dir}/model-config.py\")\n",
    "\n",
    "# Show the saved config\n",
    "!cat $work_dir/model-config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBXYc-w3W7TF",
    "outputId": "faaf7fa5-753c-4cfe-d952-792e46a1be9c"
   },
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "import os.path as osp\n",
    "\n",
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = CLASSES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76I0qhnOW7TG",
    "outputId": "54f360cf-3893-4e9a-d737-ec62bf9715c8"
   },
   "outputs": [],
   "source": [
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTC7H3QdpNlC"
   },
   "source": [
    "# Export to Open Neural Network Exchange (ONNX Format)\n",
    "\n",
    "You will need\n",
    "\n",
    "1. The image shape the model expects you can get this from the model config under the `train_pipeline` field. It should look something like:\n",
    "\n",
    "```python\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
    "                                   ‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qLgVNczmOjq",
    "outputId": "07a12a02-9e56-4940-8703-6837b1e70cab"
   },
   "outputs": [],
   "source": [
    "# NOTE: shape is in the order of; HEIGHT WIDHT\n",
    "# ALSO: This produces a lot of output. If the export\n",
    "#       is Successfull you'll get a message:\n",
    "#       Successfully exported ONNX model: work_dir/model.onnx\n",
    "\n",
    "!python mmdetection/tools/deployment/pytorch2onnx.py \\\n",
    "  $work_dir/model-config.py \\\n",
    "  zzz_work_dir/latest.pth \\\n",
    "  --output-file $work_dir/model.onnx \\\n",
    "  --shape 1333 800 \\\n",
    "  --show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLCrocmAyHgT"
   },
   "source": [
    "# Perform Inference With Onnx Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Osx4V3A2pgiq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from highlighter_client.io import write_image\n",
    "import onnx\n",
    "from mmdet.core.export import preprocess_example_input\n",
    "from mmdet.core.export.model_wrappers import ONNXRuntimeDetector\n",
    "\n",
    "# Select random image from test set\n",
    "image_filename = ds.images_df[ds.images_df.split == \"test\"].filename.sample(n=1).values[0]\n",
    "image_path = f\"{image_dir}/{image_filename}\"\n",
    "\n",
    "# Define pre-processing steps \n",
    "image_shape = (1333, 800)  # <-- NOTE: This needs to be the shape defined when you exported the ONNX model\n",
    "input_config = {'input_shape': (1,3,image_shape[0],image_shape[1]),\n",
    "                'input_path': image_path,\n",
    "                'normalize_cfg': cfg.img_norm_cfg,}\n",
    "\n",
    "# Perform pre-processing\n",
    "one_img, one_meta = preprocess_example_input(input_config)\n",
    "img_list, img_meta_list = [one_img], [[one_meta]]\n",
    "img_list = [_.cuda().contiguous() for _ in img_list]\n",
    "\n",
    "# Instantiate Model\n",
    "onnx_model_file = f\"{work_dir}/model.onnx\"\n",
    "onnx_model = ONNXRuntimeDetector(onnx_model_file, \n",
    "                                 class_names=np.array(CLASSES), \n",
    "                                 device_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ze2oT97M2GHm",
    "outputId": "73621bc1-b7c7-49b0-eb7b-6c7f002aa0ff"
   },
   "outputs": [],
   "source": [
    "# Run Model\n",
    "\"\"\"\n",
    "Note output shape [num_images, num_detections, 5]\n",
    "\n",
    "Where the first 4 elements of each inner list represent a bbox the 5th\n",
    "represents the confidence\n",
    "\n",
    "[\n",
    "  [\n",
    "    [x0,y0,x1,y1,conf],\n",
    "    [x0,y0,x1,y1,conf],\n",
    "    ...\n",
    "  ]\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "onnx_results = onnx_model(img_list, img_metas=img_meta_list, return_loss=False)[0]\n",
    "onnx_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJLkW2f22SR3"
   },
   "outputs": [],
   "source": [
    "show_img = one_meta['show_img']\n",
    "score_thr=0.0\n",
    "output_inferences_file = \"test_image_overlay.jpg\"\n",
    "onnx_model.show_result(\n",
    "            show_img,\n",
    "            onnx_results,\n",
    "            score_thr=score_thr,\n",
    "            show=True,\n",
    "            win_name='ONNXRuntime',\n",
    "            out_file=output_inferences_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WNEFaTAb3JjG",
    "outputId": "b834f3c4-08b2-4177-ecfc-6901b3872b21"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(output_inferences_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train_mmdetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
